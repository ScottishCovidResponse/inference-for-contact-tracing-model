#!/bin/bash

#! sbatch directives begin here ###############################
#! Name of the job:
#SBATCH -J inference-for-contact-tracing-model
#! Charge the SCRC project:
#SBATCH -A DIRAC-DC003-CPU

#! Simple single core jobs use one node and one task
#SBATCH --nodes=1
#SBATCH --ntasks=1

#! Set a time limit (e.g. 5 minutes)
#! TODO: Ensure this time limit is not too short for your jobs
#SBATCH --time=00:05:00

#! Set --mail-type=FAIL to get an email if the job array fails
#SBATCH --mail-type=FAIL

#! Maximum memory should be 6GB or 12GB
#SBATCH --mem=5980mb
#! For 6GB per CPU, set "-p skylake"; for 12GB per CPU, set "-p skylake-himem": 
#SBATCH -p skylake

#! Note: Charging is determined by core number*walltime (doubled for 12GB per CPU)

#! This submits a job array with a range of index values --array=[first]-[last]:[step]
#! ("--array=0-15:4" is equivalent to "--array=0,4,8,12")
#! TODO: Set your required job array here (with the required number of jobs and
#!       a step size equal to the number of iterations in each job)
#SBATCH --array=0-1:1

#! sbatch directives end here (put any additional directives above this line)

#! Setup the environment seen by the application
#! (note that SLURM reproduces the environment at submission irrespective of ~/.bashrc):
. /etc/profile.d/modules.sh                # Enable the module command
module purge                               # Remove all modules still loaded
module load rhel7/default-peta4            # Load the basic (required) environment
module python                              # Load python
#module load jdk-8u141-b15-intel-17.0.4-3g6rhr2 # Load Java

#! These folders should be modified to match with each user's environment
export PYTHONPATH=${PYTHONPATH}:${python_project_dir}/src
export JAVA_HOME=${HOME}/jdk-14.0.1
python_project_dir="${HOME}/git/inference-for-contact-tracing-model"
java_project_dir="${HOME}/git/Contact-Tracing-Model"

#! Create a folder for each array job
#! SLURM_SUBMIT_DIR is the directory in which sbatch is run
#! SLURM_ARRAY_TASK_ID is the array index for each job
#! SLURM_ARRAY_JOB_ID is the job array's master job ID number
work_dir="${HOME}/covid-19/draw_${SLURM_ARRAY_JOB_ID}_${SLURM_ARRAY_TASK_ID}"
mkdir -p ${work_dir}
cd ${python_project_dir}

#! Set file paths for output to stdout and stderr:
#! %A means slurm job ID and %a means array index
#! (Note: It appears that these can _not_ go in the folders we create for each job)
#SBATCH --output=${work_dir}/job_%A_%a_std.out
#SBATCH --error=${work_dir}/job_%A_%a_std.err

python src/draw_parameters.py ${work_dir} \
	--job-name=draw_${SLURM_ARRAY_JOB_ID}_${SLURM_ARRAY_TASK_ID} \
	--java-project-dir=${java_project_dir} \
	--n-simulations=1000 \
	--output-summary-file=Compartments.csv \
	--seed=${SLURM_ARRAY_JOB_ID}${SLURM_ARRAY_TASK_ID}
