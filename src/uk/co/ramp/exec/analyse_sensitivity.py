"""Parameter Sensitivity Analysis for Contact Tracing Model
Sample pairs of (parameters, output summary) must be generated by param_samples.py in advance.

Usage:
  analyse_sensitivity.py <INPUT_DIR> <OUTPUT_DIR> [--seed=<seed>]
  analyse_sensitivity.py (-h | --help)
  analyse_sensitivity.py --version

Options:
  -h --help                       Show this screen.
  --version                       Show version.
  --seed=<seed>                   Random seed [default: 1234].
  
"""

import numpy as np
import pandas as pd
import os
from docopt import docopt
from sklearn.ensemble import ExtraTreesRegressor
import shap
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt

if __name__ == '__main__':
    args = docopt(__doc__, version='0.0.1')
    
    def _getopt(key, default):
        return args[key] if key in args and args[key] is not None else default

    indir = _getopt('<INPUT_DIR>', None)
    outdir = _getopt('<OUTPUT_DIR>', None)
    seed = int(_getopt('--seed', 1234))

    X = pd.read_csv('{}/input_parameter_samples.csv'.format(indir))
    Y = pd.read_csv('{}/output_loss_samples.csv'.format(indir))
    X = X.set_index(X.columns[0])
    Y = Y.set_index(Y.columns[0])
    
    n = X.shape[0]
    
    ms_list = np.unique(np.round(np.logspace(np.log10(2.0), np.log10(np.min([1000, n / 2])), 10)).astype(int))

    try:
        os.mkdir(outdir)
    except:
        pass

    imp_biased = []
    imp_unbiased = []
    for metric in Y.columns:
        # Step 1. Fitting a non-linear extra-trees regressor with out-of-bag model selection
        oob_score = [ExtraTreesRegressor(
            n_estimators=100,
            criterion='mse',
            max_depth=None,
            bootstrap=True,
            oob_score=True,
            min_samples_split=ms,
            random_state=seed).fit(X, Y[metric]).oob_score_ for ms in ms_list]
        best_ms = ms_list[np.argmin(oob_score)]
    
        model = ExtraTreesRegressor(
            n_estimators=300,
            criterion='mse',
            max_depth=None,
            bootstrap=True,
            oob_score=True,
            min_samples_split=best_ms,
            random_state=seed).fit(X, Y[metric])
        
        # This is a biased but useful importance estimate.
        fimp = model.feature_importances_
        fimp /= fimp.sum()
        imp_biased.append(fimp.reshape(-1, 1))
    
        # This is an unbiased but high-variance estimate.
        model0 = ExtraTreesRegressor(
            n_estimators=300,
            criterion='mse',
            max_features=int(1),
            max_depth=None,
            bootstrap=True,
            oob_score=True,
            min_samples_split=best_ms,
            random_state=seed).fit(X, Y[metric])
        fimp = model0.feature_importances_
        fimp /= fimp.sum()
        imp_unbiased.append(fimp.reshape(-1, 1))
        
        explainer = shap.TreeExplainer(model)
        shap_values = explainer.shap_values(X)
        
        with PdfPages('{}/{}.pdf'.format(outdir, metric)) as pdf:
            plt.figure(figsize=(6, 6))
            shap.summary_plot(shap_values, X, show=False)
            plt.title('Datapoint-specific sensitivities to {}'.format(metric))
            pdf.savefig()
            plt.close()

            for xcol in X.columns:
                plt.figure(figsize=(6, 6))
                shap.dependence_plot(xcol, shap_values, X, show=False)
                plt.title('How interaction with {} affects {}'.format(xcol, metric))
                pdf.savefig()
                plt.close()
        
    imp_biased = pd.DataFrame(
        data=np.hstack(tuple(imp_biased)),
        index=X.columns,
        columns=Y.columns
        )
    imp_unbiased = pd.DataFrame(
        data=np.hstack(tuple(imp_unbiased)),
        index=X.columns,
        columns=Y.columns
        )

    imp_biased.to_csv('{}/relative_importance.biased.csv'.format(outdir))
    imp_unbiased.to_csv('{}/relative_importance.unbiased.csv'.format(outdir))
        
