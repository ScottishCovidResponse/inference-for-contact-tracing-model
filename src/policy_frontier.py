"""Draw an efficient frontier on policy parameters of Contact Tracing Model
Sample pairs of (parameters, output summary) must be generated by draw_parameters.py, and
predictive models must be fitted by analyse_sensitivity.py in advance.

Usage:
  policy_frontier.py <WORK_DIR> [--output-prefix=<PREFIX>] [--metricA=<output_metric>] [--metricB=<output_metric>] [--seed=<seed>] [--n-jobs=<njobs>]
  policy_frontier.py (-h | --help)
  policy_frontier.py --version

Options:
  -h --help                       Show this screen.
  --version                       Show version.
  --output-prefix=<PREFIX>        Prefix of output files [default: frontier].
  --metricA=<output_metric>       Metric (column name) to be minimised. Chosen as the X-axis of the frontier plot [default: person_days_in_isolation].
  --metricB=<output_metric>       Metric (column name) to be minimised. Chosen as the Y-axis of the frontier plot [default: total_death].
  --seed=<seed>                   Random seed [default: 1234].
  --n-jobs=<njobs>               Number of threads in fitting a meta model [default: 1].
  
"""

import numpy as np
import pandas as pd
import multiprocessing
from scipy.interpolate import interp1d
import os
from docopt import docopt
from six.moves import cPickle as pickle
from sklearn.utils import check_random_state
import shap
from matplotlib.backends.backend_pdf import PdfPages
import matplotlib.pyplot as plt
from uk.co.ramp.gencfg.isolation_policies import IsolationPolicies
from uk.co.ramp.gencfg.tracing_policies import TracingPolicies


def fit_frontier(case_loss, X, policy_parameter_columns, score_columns, seed):
    x_sorted = np.sort(case_loss[:, 0])
    old_th = None
    
    frontier_policies = []
    frontier_scores = []
    for j, x_th in enumerate(x_sorted):
        filt = case_loss[:, 0] <= x_th
        th = np.arange(n)[filt][case_loss[filt, 1].argmin()]
        y_th = case_loss[th, 1]
        policy_th = X[policy_parameter_columns].iloc[th].values
        if old_th is None or th != old_th:  # new trade-off point
            frontier_policies.append(policy_th.reshape(1, -1))
            frontier_scores.append(np.array([x_th, y_th]).reshape(1, -1))
        old_th = th
        
    frontier_policies = pd.DataFrame(
        data=np.vstack(frontier_policies),
        columns=policy_parameter_columns
    )
    frontier_scores = pd.DataFrame(
        data=np.vstack(frontier_scores),
        columns=score_columns
    )
        
    # Fit the efficient frontier curve
    frontier_line = interp1d(frontier_scores[score_columns[0]], frontier_scores[score_columns[1]], kind='linear')
        
    return frontier_policies, frontier_scores, frontier_line


def calcstat(X, indices, workdir, metricA, metricB, policy_parameter_columns, k, random_state):
    with open('{}/{}.model'.format(workdir, metricA), 'rb') as fin:
        modelA = pickle.load(fin)
    with open('{}/{}.model'.format(workdir, metricB), 'rb') as fin:
        modelB = pickle.load(fin)

    n = X.shape[0]
    result = np.zeros((len(indices), 4))
    for row, i in enumerate(indices):
        xpolicy_i = X[policy_parameter_columns].iloc[i].values
        X_i = X.iloc[random_state.choice(n, size=k)].copy()
        X_i[policy_parameter_columns] = np.vstack([xpolicy_i.reshape(1, -1) for _ in range(k)])
        yA = modelA.predict(X_i)
        yB = modelB.predict(X_i)
        meanA = np.mean(yA)
        meanB = np.mean(yB)
        q99A = np.percentile(yA, 99.0)
        q99B = np.percentile(yB, 99.0)
        
        result[row, 0] = meanA
        result[row, 1] = meanB
        result[row, 2] = q99A
        result[row, 3] = q99B
    
    return result


if __name__ == '__main__':
    args = docopt(__doc__, version='0.0.1')
    
    def _getopt(key, default):
        return args[key] if key in args and args[key] is not None else default

    workdir = _getopt('<WORK_DIR>', None)
    seed = int(_getopt('--seed', 1234))
    n_jobs = int(_getopt('--n-jobs', 1))
    outprefix = _getopt('--output-prefix', 'frontier')
    metricA = _getopt('--metricA', 'person_days_in_isolation')
    metricB = _getopt('--metricB', 'total_death')

    X = pd.read_csv('{}/input_parameter_samples.csv'.format(workdir), index_col=0)

    policy_parameter_columns = []
    isopolicy = IsolationPolicies(random_state=seed)
    tracepolicy = TracingPolicies(random_state=seed)
    for key in isopolicy.next().keys():
        policy_parameter_columns.append(key)
    for key in tracepolicy.next().keys():
        policy_parameter_columns.append(key)
    
    n = X.shape[0]
    k = n if n <= 1000 else 1000
    
    average_case_loss = np.zeros((n, 2))
    worst_case_loss = np.zeros((n, 2))

    if n_jobs > 1:   
        with multiprocessing.Pool(processes=n_jobs) as pool:
            indices = [np.arange(n)[i::n_jobs] for i in range(int(n / n_jobs))]
            arglist = []
            for j in range(n_jobs):
                random_state_j = check_random_state(seed + j)
                arglist.append((X, indices[j], workdir, metricA, metricB, policy_parameter_columns, k, random_state_j))
            results = pool.starmap(calcstat, arglist)
            for j in range(n_jobs):
                average_case_loss[indices[j], :] = results[j][:, [0, 1]]
                worst_case_loss[indices[j], :] = results[j][:, [2, 3]]
    else:
        random_state = check_random_state(seed)
        results = calcstat(X, np.arange(n), workdir, metricA, metricB, policy_parameter_columns, k, random_state)
        average_case_loss[:, :] = results[:, [0, 1]]
        worst_case_loss[:, :] = results[:, [2, 3]]
        
    # Identify the best empirical trade-off points (X, Y) = (x, y=min_Y Y | X<=x)
    avg_score_columns = ['E[{}]'.format(metricA), 'E[{}]'.format(metricB)]
    avg_frontier_policies, avg_frontier_scores, avg_frontier_line = fit_frontier(
        average_case_loss, X, policy_parameter_columns, avg_score_columns, seed)
    avg_xrange = np.linspace(avg_frontier_line.x.min(), avg_frontier_line.x.max(), 1000)
    
    worst_score_columns = ['Q99[{}]'.format(metricA), 'Q99[{}]'.format(metricB)]
    worst_frontier_policies, worst_frontier_scores, worst_frontier_line = fit_frontier(
        worst_case_loss, X, policy_parameter_columns, worst_score_columns, seed)
    worst_xrange = np.linspace(worst_frontier_line.x.min(), worst_frontier_line.x.max(), 1000)
    
    with PdfPages('{}/{}.tradeoffs.pdf'.format(workdir, outprefix)) as pdf:
        plt.figure(figsize=(6, 6))
        plt.scatter(average_case_loss[:, 0], average_case_loss[:, 1])
        plt.plot(avg_xrange, avg_frontier_line(avg_xrange), color='blue', linewidth=2)
        plt.subplots_adjust(left=0.18, bottom=0.12, right=0.98, top=0.92)
        plt.title('Average-case Efficient Frontier')
        plt.xlabel(avg_score_columns[0])
        plt.ylabel(avg_score_columns[1])
        pdf.savefig()
        plt.close()

        plt.figure(figsize=(6, 6))
        plt.scatter(worst_case_loss[:, 0], worst_case_loss[:, 1])
        plt.plot(worst_xrange, worst_frontier_line(worst_xrange), color='blue', linewidth=2)
        plt.subplots_adjust(left=0.18, bottom=0.12, right=0.98, top=0.92)
        plt.title('Worst-case (99%-tile-based) Efficient Frontier')
        plt.xlabel(worst_score_columns[0])
        plt.ylabel(worst_score_columns[1])
        pdf.savefig()
        plt.close()
        
    pd.concat([avg_frontier_policies, avg_frontier_scores], axis=1).to_csv('{}/{}.average_case_policies.csv'.format(workdir, outprefix))
    pd.concat([worst_frontier_policies, worst_frontier_scores], axis=1).to_csv('{}/{}.worst_case_policies.csv'.format(workdir, outprefix))
        
